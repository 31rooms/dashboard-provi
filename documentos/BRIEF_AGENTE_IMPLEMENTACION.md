# Brief para Agente: Implementaci√≥n Completa Dashboard Kommo ‚Üí Looker Studio

## üéØ OBJETIVO DEL PROYECTO

Crear un sistema automatizado que sincronice datos de **Kommo CRM** a **Supabase (PostgreSQL)** y los visualice en **Looker Studio**.

---

## üìã ENTREGABLES REQUERIDOS

### 1. Setup de Supabase ‚úÖ
- [ ] Crear todas las tablas necesarias en Supabase
- [ ] Crear vistas optimizadas para Looker Studio
- [ ] Crear funciones para c√°lculos autom√°ticos
- [ ] Configurar √≠ndices para performance
- [ ] Validar que todo est√© funcionando

### 2. Script JavaScript de Sincronizaci√≥n üìù
- [ ] Script `kommo-sync.js` que:
  - Se conecte a Kommo API
  - Extraiga leads, eventos, usuarios, pipelines
  - Transforme los datos al formato correcto
  - Guarde en Supabase con UPSERTS
  - Calcule m√©tricas (tiempos de respuesta, conversiones)
  - Maneje errores y logging
  - Soporte modo FULL (carga inicial) y modo INCREMENTAL
  - Sea ejecutable en cualquier servidor Node.js
  - Sea f√°cilmente migrable a n8n

### 3. Carga Inicial de Datos üîÑ
- [ ] Ejecutar script en modo FULL
- [ ] Cargar todos los leads hist√≥ricos
- [ ] Cargar todos los eventos hist√≥ricos
- [ ] Verificar integridad de datos
- [ ] Generar reporte de carga

### 4. Configuraci√≥n de Looker Studio üìä
- [ ] Documento con instrucciones paso a paso
- [ ] Screenshots de c√≥mo conectar Supabase
- [ ] Queries SQL recomendadas
- [ ] Template de dashboard (opcional)

---

## üîß TECNOLOG√çAS A USAR

| Componente | Tecnolog√≠a | Versi√≥n |
|------------|------------|---------|
| **Base de datos** | Supabase (PostgreSQL) | Latest |
| **Script** | Node.js | ‚â•18.x |
| **Lenguaje** | JavaScript (CommonJS o ESM) | ES2022+ |
| **HTTP Client** | axios o fetch | Latest |
| **Supabase Client** | @supabase/supabase-js | ^2.x |
| **Environment vars** | dotenv | ^16.x |
| **Logging** | console + file logging | - |
| **Visualizaci√≥n** | Google Looker Studio | - |

---

## üìÇ ESTRUCTURA DE ARCHIVOS ESPERADA

```
kommo-supabase-sync/
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .env (no commitear)
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ index.js (punto de entrada)
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ supabase.js (configuraci√≥n Supabase)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ kommo.js (configuraci√≥n Kommo)
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kommo.service.js (API de Kommo)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ supabase.service.js (operaciones Supabase)
‚îÇ   ‚îú‚îÄ‚îÄ transformers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ leads.transformer.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ events.transformer.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ conversions.transformer.js
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ helpers.js
‚îÇ   ‚îî‚îÄ‚îÄ sync/
‚îÇ       ‚îú‚îÄ‚îÄ full-sync.js (carga inicial completa)
‚îÇ       ‚îî‚îÄ‚îÄ incremental-sync.js (sincronizaci√≥n incremental)
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îî‚îÄ‚îÄ sync.log
‚îî‚îÄ‚îÄ scripts/
    ‚îî‚îÄ‚îÄ setup-supabase.sql (SQL para crear tablas)
```

---

## üóÑÔ∏è CONFIGURACI√ìN DE SUPABASE

### Paso 1: Crear Tablas

**Archivo:** Ya existe `supabase_setup.sql` en el proyecto

**Acci√≥n:**
1. Abrir Supabase Dashboard
2. Ir a SQL Editor
3. Copiar el contenido de `supabase_setup.sql`
4. Ejecutar
5. Verificar que se crearon:
   - 9 tablas (leads, events, conversions, response_times, users, pipelines, pipeline_statuses, meta_campaigns, meta_daily_metrics)
   - 4 vistas (looker_leads_complete, funnel_conversion, user_performance, daily_metrics)
   - 2 funciones (calculate_response_times, calculate_conversions)

### Paso 2: Obtener Credenciales

En Supabase Dashboard ‚Üí Settings ‚Üí API:

```
SUPABASE_URL=https://xxxxx.supabase.co
SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
```

**Importante:** Usar `SERVICE_ROLE_KEY` para el script (tiene permisos completos)

---

## üîë CREDENCIALES NECESARIAS

### Archivo: `.env`

```bash
# Kommo API
KOMMO_SUBDOMAIN=gerenciaventasgrupoprovicommx
KOMMO_ACCESS_TOKEN=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImp0aSI6ImUwNmQz...

# Supabase
SUPABASE_URL=https://xxxxx.supabase.co
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...

# Configuraci√≥n de Sync
SYNC_MODE=incremental # full | incremental
SYNC_BATCH_SIZE=250
SYNC_DELAY_MS=1000
LOG_LEVEL=info # debug | info | warn | error
```

---

## üìù ESPECIFICACIONES DEL SCRIPT

### `kommo-sync.js` - Funcionalidades Requeridas

#### 1. Configuraci√≥n y Setup

```javascript
// package.json
{
  "name": "kommo-supabase-sync",
  "version": "1.0.0",
  "type": "module", // o "commonjs" seg√∫n preferencia
  "scripts": {
    "sync": "node src/index.js",
    "sync:full": "SYNC_MODE=full node src/index.js",
    "sync:incremental": "node src/index.js"
  },
  "dependencies": {
    "@supabase/supabase-js": "^2.39.0",
    "axios": "^1.6.0",
    "dotenv": "^16.3.0"
  }
}
```

#### 2. Estructura del Script Principal

```javascript
// src/index.js

import { config } from './config/environment.js';
import { KommoService } from './services/kommo.service.js';
import { SupabaseService } from './services/supabase.service.js';
import { logger } from './utils/logger.js';
import { fullSync } from './sync/full-sync.js';
import { incrementalSync } from './sync/incremental-sync.js';

async function main() {
  try {
    logger.info('üöÄ Iniciando sincronizaci√≥n Kommo ‚Üí Supabase');
    logger.info(`üìä Modo: ${config.syncMode}`);

    const kommoService = new KommoService(config.kommo);
    const supabaseService = new SupabaseService(config.supabase);

    // Verificar conexiones
    await supabaseService.testConnection();
    await kommoService.testConnection();

    // Ejecutar sincronizaci√≥n seg√∫n modo
    if (config.syncMode === 'full') {
      await fullSync(kommoService, supabaseService);
    } else {
      await incrementalSync(kommoService, supabaseService);
    }

    logger.info('‚úÖ Sincronizaci√≥n completada exitosamente');
    process.exit(0);

  } catch (error) {
    logger.error('‚ùå Error en sincronizaci√≥n:', error);
    process.exit(1);
  }
}

main();
```

#### 3. Servicio de Kommo API

**M√©todos requeridos:**

```javascript
class KommoService {
  async getLeads(params) { }
  async getEvents(params) { }
  async getUsers() { }
  async getPipelines() { }
  async getLeadById(id) { }
  async getContact(id) { }

  // M√©todos con paginaci√≥n autom√°tica
  async getAllLeads(filters) { }
  async getAllEvents(filters) { }
}
```

**Caracter√≠sticas:**
- Manejo autom√°tico de paginaci√≥n
- Rate limiting (respeto de 7 req/seg)
- Retry con exponential backoff
- Cache de pipelines/usuarios (no cambian frecuentemente)

#### 4. Servicio de Supabase

**M√©todos requeridos:**

```javascript
class SupabaseService {
  // UPSERT (actualizar o insertar)
  async upsertLeads(leads) { }
  async upsertEvents(events) { }
  async upsertUsers(users) { }
  async upsertPipelines(pipelines) { }

  // Lecturas
  async getLastSyncTimestamp() { }
  async getLeadIds() { }

  // C√°lculos
  async calculateResponseTimes() { }
  async calculateConversions() { }

  // Utilidades
  async testConnection() { }
  async getStats() { }
}
```

**Caracter√≠sticas:**
- Batch inserts (250 registros a la vez)
- Manejo de errores con retry
- Logging de queries lentas

#### 5. Transformadores de Datos

**LeadsTransformer:**

```javascript
// Entrada: Lead raw de Kommo API
// Salida: Objeto para tabla 'leads' en Supabase

function transformLead(kommoLead, pipelines, users) {
  return {
    id: kommoLead.id,
    name: kommoLead.name,
    pipeline_id: kommoLead.pipeline_id,
    pipeline_name: pipelines[kommoLead.pipeline_id]?.name,
    status_id: kommoLead.status_id,
    status_name: getStatusName(kommoLead.status_id, pipelines),
    responsible_user_id: kommoLead.responsible_user_id,
    responsible_user_name: users[kommoLead.responsible_user_id]?.name,
    price: kommoLead.price || 0,
    created_at: new Date(kommoLead.created_at * 1000).toISOString(),
    updated_at: new Date(kommoLead.updated_at * 1000).toISOString(),
    closed_at: kommoLead.closed_at ? new Date(kommoLead.closed_at * 1000).toISOString() : null,
    is_deleted: kommoLead.is_deleted || false,

    // Custom fields
    utm_source: getCustomField(kommoLead, 1681790),
    utm_campaign: getCustomField(kommoLead, 1681788),
    utm_medium: getCustomField(kommoLead, 1681786),
    desarrollo: getCustomField(kommoLead, 2093484),
    modelo: getCustomField(kommoLead, 2093544),

    // Contact info (si est√° embebido)
    contact_name: kommoLead._embedded?.contacts?.[0]?.name,
    contact_email: getContactEmail(kommoLead),
    contact_phone: getContactPhone(kommoLead),

    last_synced_at: new Date().toISOString()
  };
}
```

**EventsTransformer:**

```javascript
function transformEvent(kommoEvent, users) {
  return {
    id: kommoEvent.id,
    lead_id: kommoEvent.entity_id,
    event_type: kommoEvent.type,
    created_at: new Date(kommoEvent.created_at * 1000).toISOString(),
    created_by_id: kommoEvent.created_by,
    created_by_name: users[kommoEvent.created_by]?.name || 'Sistema',
    value_before: kommoEvent.value_before || null,
    value_after: kommoEvent.value_after || null,
    last_synced_at: new Date().toISOString()
  };
}
```

#### 6. Flujo de Full Sync (Carga Inicial)

```javascript
async function fullSync(kommoService, supabaseService) {
  logger.info('üì¶ Iniciando FULL SYNC (carga completa)');

  const stats = {
    users: 0,
    pipelines: 0,
    leads: 0,
    events: 0,
    errors: []
  };

  try {
    // 1. Sincronizar usuarios
    logger.info('üë• Sincronizando usuarios...');
    const users = await kommoService.getUsers();
    await supabaseService.upsertUsers(users);
    stats.users = users.length;
    logger.info(`‚úì ${users.length} usuarios sincronizados`);

    // 2. Sincronizar pipelines
    logger.info('üìä Sincronizando pipelines...');
    const pipelines = await kommoService.getPipelines();
    await supabaseService.upsertPipelines(pipelines);
    stats.pipelines = pipelines.length;
    logger.info(`‚úì ${pipelines.length} pipelines sincronizados`);

    // 3. Sincronizar leads (con paginaci√≥n)
    logger.info('üìã Sincronizando leads...');
    let page = 1;
    let hasMore = true;

    while (hasMore) {
      const leadsPage = await kommoService.getLeads({
        limit: 250,
        page
      });

      if (leadsPage.length === 0) {
        hasMore = false;
        break;
      }

      const transformedLeads = leadsPage.map(lead =>
        transformLead(lead, pipelines, users)
      );

      await supabaseService.upsertLeads(transformedLeads);
      stats.leads += leadsPage.length;

      logger.info(`‚úì P√°gina ${page}: ${leadsPage.length} leads sincronizados (total: ${stats.leads})`);

      page++;
      await sleep(1000); // Rate limiting
    }

    // 4. Sincronizar eventos (√∫ltimos 90 d√≠as)
    logger.info('üìÖ Sincronizando eventos...');
    const dateFrom = new Date();
    dateFrom.setDate(dateFrom.getDate() - 90);

    const events = await kommoService.getAllEvents({
      filter: {
        created_at: {
          from: Math.floor(dateFrom.getTime() / 1000)
        }
      }
    });

    const transformedEvents = events.map(event =>
      transformEvent(event, users)
    );

    await supabaseService.upsertEvents(transformedEvents);
    stats.events = events.length;
    logger.info(`‚úì ${events.length} eventos sincronizados`);

    // 5. Calcular m√©tricas
    logger.info('üî¢ Calculando m√©tricas...');
    await supabaseService.calculateResponseTimes();
    await supabaseService.calculateConversions();
    logger.info('‚úì M√©tricas calculadas');

    // 6. Reporte final
    logger.info('üìä RESUMEN DE SINCRONIZACI√ìN:');
    logger.info(`   Usuarios: ${stats.users}`);
    logger.info(`   Pipelines: ${stats.pipelines}`);
    logger.info(`   Leads: ${stats.leads}`);
    logger.info(`   Eventos: ${stats.events}`);

    return stats;

  } catch (error) {
    logger.error('Error en full sync:', error);
    throw error;
  }
}
```

#### 7. Flujo de Incremental Sync (Sincronizaci√≥n Regular)

```javascript
async function incrementalSync(kommoService, supabaseService) {
  logger.info('üîÑ Iniciando INCREMENTAL SYNC');

  try {
    // 1. Obtener √∫ltima sincronizaci√≥n
    const lastSync = await supabaseService.getLastSyncTimestamp();
    logger.info(`üìÖ √öltima sincronizaci√≥n: ${lastSync}`);

    // 2. Obtener leads actualizados
    const updatedLeads = await kommoService.getLeads({
      filter: {
        updated_at: {
          from: Math.floor(new Date(lastSync).getTime() / 1000)
        }
      }
    });

    logger.info(`üìã Leads actualizados: ${updatedLeads.length}`);

    if (updatedLeads.length > 0) {
      const users = await supabaseService.getCachedUsers();
      const pipelines = await supabaseService.getCachedPipelines();

      const transformedLeads = updatedLeads.map(lead =>
        transformLead(lead, pipelines, users)
      );

      await supabaseService.upsertLeads(transformedLeads);
    }

    // 3. Obtener eventos nuevos
    const newEvents = await kommoService.getEvents({
      filter: {
        created_at: {
          from: Math.floor(new Date(lastSync).getTime() / 1000)
        }
      }
    });

    logger.info(`üìÖ Eventos nuevos: ${newEvents.length}`);

    if (newEvents.length > 0) {
      const users = await supabaseService.getCachedUsers();
      const transformedEvents = newEvents.map(event =>
        transformEvent(event, users)
      );

      await supabaseService.upsertEvents(transformedEvents);
    }

    // 4. Recalcular m√©tricas solo para leads actualizados
    if (updatedLeads.length > 0) {
      logger.info('üî¢ Recalculando m√©tricas para leads actualizados...');
      const leadIds = updatedLeads.map(l => l.id);
      await supabaseService.calculateResponseTimesForLeads(leadIds);
      await supabaseService.calculateConversionsForLeads(leadIds);
    }

    logger.info('‚úÖ Sincronizaci√≥n incremental completada');

  } catch (error) {
    logger.error('Error en incremental sync:', error);
    throw error;
  }
}
```

#### 8. Logger con Archivo

```javascript
// src/utils/logger.js

import fs from 'fs';
import path from 'path';

class Logger {
  constructor() {
    this.logFile = path.join(process.cwd(), 'logs', 'sync.log');
    this.ensureLogDir();
  }

  ensureLogDir() {
    const logDir = path.dirname(this.logFile);
    if (!fs.existsSync(logDir)) {
      fs.mkdirSync(logDir, { recursive: true });
    }
  }

  log(level, message, data = null) {
    const timestamp = new Date().toISOString();
    const logMessage = `[${timestamp}] [${level.toUpperCase()}] ${message}`;

    // Console
    console.log(logMessage);
    if (data) console.log(data);

    // File
    const fileMessage = data
      ? `${logMessage}\n${JSON.stringify(data, null, 2)}\n`
      : `${logMessage}\n`;

    fs.appendFileSync(this.logFile, fileMessage);
  }

  info(message, data) { this.log('info', message, data); }
  warn(message, data) { this.log('warn', message, data); }
  error(message, data) { this.log('error', message, data); }
  debug(message, data) { this.log('debug', message, data); }
}

export const logger = new Logger();
```

#### 9. Manejo de Errores

**Caracter√≠sticas requeridas:**
- Retry con exponential backoff para errores de red
- Log detallado de errores en archivo
- Continuar sincronizaci√≥n aunque falle un lead/evento individual
- Reporte de errores al final

```javascript
async function withRetry(fn, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await fn();
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      const delay = Math.pow(2, i) * 1000;
      logger.warn(`Intento ${i + 1} fall√≥, reintentando en ${delay}ms...`);
      await sleep(delay);
    }
  }
}
```

---

## üöÄ PROCESO DE EJECUCI√ìN

### Primera Vez (Carga Inicial)

```bash
# 1. Instalar dependencias
npm install

# 2. Configurar .env
cp .env.example .env
# Editar .env con credenciales reales

# 3. Ejecutar setup de Supabase (manual, una sola vez)
# Copiar supabase_setup.sql en SQL Editor de Supabase

# 4. Ejecutar carga inicial
npm run sync:full
```

**Salida esperada:**
```
üöÄ Iniciando sincronizaci√≥n Kommo ‚Üí Supabase
üìä Modo: full
‚úì Conexi√≥n a Supabase exitosa
‚úì Conexi√≥n a Kommo API exitosa
üì¶ Iniciando FULL SYNC (carga completa)
üë• Sincronizando usuarios...
‚úì 16 usuarios sincronizados
üìä Sincronizando pipelines...
‚úì 37 pipelines sincronizados
üìã Sincronizando leads...
‚úì P√°gina 1: 250 leads sincronizados (total: 250)
‚úì P√°gina 2: 250 leads sincronizados (total: 500)
‚úì P√°gina 3: 150 leads sincronizados (total: 650)
üìÖ Sincronizando eventos...
‚úì 15,234 eventos sincronizados
üî¢ Calculando m√©tricas...
‚úì M√©tricas calculadas
üìä RESUMEN DE SINCRONIZACI√ìN:
   Usuarios: 16
   Pipelines: 37
   Leads: 650
   Eventos: 15,234
‚úÖ Sincronizaci√≥n completada exitosamente
```

### Ejecuciones Subsecuentes (Incremental)

```bash
npm run sync
```

**Duraci√≥n esperada:**
- Full sync: 10-30 minutos (dependiendo de cantidad de datos)
- Incremental sync: 30 segundos - 2 minutos

---

## üìä CONFIGURACI√ìN DE LOOKER STUDIO

### Documento de Configuraci√≥n

Crear archivo: `LOOKER_STUDIO_SETUP.md` con:

#### 1. Conexi√≥n a Supabase desde Looker Studio

**Paso 1: Crear Fuente de Datos**

1. Ir a [Looker Studio](https://lookerstudio.google.com)
2. Click en **"Crear"** ‚Üí **"Fuente de datos"**
3. Buscar **"PostgreSQL"** en el buscador
4. Configurar conexi√≥n:

```
Tipo de conexi√≥n: PostgreSQL
Host: db.xxxxxxxxxxxxx.supabase.co
Puerto: 5432
Base de datos: postgres
Nombre de usuario: postgres
Contrase√±a: [contrase√±a de tu proyecto Supabase]
```

5. Habilitar **"Requerir SSL"** ‚úÖ
6. Click en **"Autenticar"**
7. Si todo est√° bien, ver√°s lista de tablas

**Paso 2: Seleccionar Vista Principal**

Seleccionar: `looker_leads_complete`

Esta vista ya incluye:
- Todos los datos del lead
- Tiempos de respuesta calculados
- Contadores de eventos
- M√©tricas de Meta Ads (cuando est√©n disponibles)

**Paso 3: Configurar Campos**

Campos calculados sugeridos:

```sql
-- ROI Porcentaje
CASE
  WHEN meta_ad_spend > 0 AND price > 0
  THEN ((price - meta_ad_spend) / meta_ad_spend) * 100
  ELSE 0
END

-- Estado de Seguimiento
CASE
  WHEN response_time_hours IS NULL THEN "Sin atender"
  WHEN response_time_hours < 1 THEN "Excelente"
  WHEN response_time_hours < 24 THEN "Bueno"
  ELSE "Mejorar"
END

-- Tiempo Legible
CASE
  WHEN response_time_hours < 1
    THEN CONCAT(CAST(response_time_minutes AS STRING), " min")
  WHEN response_time_hours < 24
    THEN CONCAT(CAST(ROUND(response_time_hours, 1) AS STRING), " hrs")
  ELSE
    CONCAT(CAST(ROUND(response_time_days, 1) AS STRING), " d√≠as")
END
```

#### 2. Dashboard Template

**P√°gina 1: Overview General**

Componentes:
- M√©trica: Total de Leads (COUNT de id)
- M√©trica: Leads con respuesta < 1hr (COUNT WHERE response_quality = 'Excelente')
- M√©trica: Valor total en pipeline (SUM de price)
- Gr√°fico de l√≠nea: Leads por d√≠a (created_at)
- Tabla: Top 10 asesores por leads (responsible_user_name, COUNT)

**P√°gina 2: Funnel de Conversi√≥n**

Conectar a vista: `funnel_conversion`

Componentes:
- Gr√°fico Sankey: from_status ‚Üí to_status
- Tabla: Conversiones por etapa
- M√©trica: Tiempo promedio por etapa

**P√°gina 3: Performance de Asesores**

Conectar a vista: `user_performance`

Componentes:
- Tabla con ranking de asesores
- Gr√°fico de barras: Leads por asesor
- Scatter plot: Tiempo de respuesta vs Leads cerrados

**P√°gina 4: An√°lisis Temporal**

Conectar a vista: `daily_metrics`

Componentes:
- Serie temporal: Leads creados por d√≠a
- Gr√°fico de √°rea: Valor acumulado
- Filtro de rango de fechas

**Filtros Globales Recomendados:**
- Pipeline (pipeline_name)
- Asesor (responsible_user_name)
- Rango de fechas (created_at)
- Estado de respuesta (response_quality)

---

## ‚úÖ CHECKLIST DE VALIDACI√ìN

Al terminar la implementaci√≥n, verificar:

### Supabase
- [ ] Todas las tablas creadas (9 tablas)
- [ ] Todas las vistas creadas (4 vistas)
- [ ] Funciones creadas (2 funciones)
- [ ] √çndices creados
- [ ] Conexi√≥n PostgreSQL funcional desde Looker Studio

### Script JavaScript
- [ ] package.json configurado
- [ ] Todas las dependencias instaladas
- [ ] .env.example creado
- [ ] README.md con instrucciones
- [ ] Script ejecutable: `npm run sync:full`
- [ ] Script ejecutable: `npm run sync`
- [ ] Logs generados en /logs/sync.log
- [ ] Manejo de errores funcionando
- [ ] Rate limiting implementado

### Carga de Datos
- [ ] Full sync ejecutado exitosamente
- [ ] Todos los usuarios cargados
- [ ] Todos los pipelines cargados
- [ ] Todos los leads cargados
- [ ] Eventos de √∫ltimos 90 d√≠as cargados
- [ ] Tiempos de respuesta calculados
- [ ] Conversiones calculadas
- [ ] Datos visibles en Supabase Dashboard

### Looker Studio
- [ ] Fuente de datos conectada
- [ ] Vista `looker_leads_complete` accesible
- [ ] Al menos 1 gr√°fico funcionando
- [ ] Filtros aplicables
- [ ] Datos actualizados visibles

---

## üìÅ ENTREGA FINAL

El agente debe entregar:

1. **Repositorio de c√≥digo** con:
   - Todos los archivos del script
   - README.md completo
   - .env.example
   - package.json

2. **Reporte de carga inicial** con:
   - Cantidad de registros cargados por tabla
   - Tiempo de ejecuci√≥n
   - Errores encontrados (si hubo)
   - Screenshots de Supabase con datos

3. **Documento de Looker Studio** con:
   - Instrucciones de conexi√≥n
   - Queries SQL √∫tiles
   - Screenshots del dashboard funcionando

4. **Video o screenshots** mostrando:
   - Script ejecut√°ndose
   - Datos en Supabase
   - Dashboard en Looker Studio

---

## üÜò SOPORTE Y REFERENCIAS

### Documentaci√≥n Oficial
- [Supabase JS Client](https://supabase.com/docs/reference/javascript/introduction)
- [Kommo API Docs](https://www.kommo.com/platform/developers/)
- [Looker Studio Help](https://support.google.com/looker-studio)

### Archivos de Referencia en el Proyecto
- `supabase_setup.sql` - SQL completo para setup
- `config.json` - Credenciales de Kommo
- `GUIA_INTEGRACION_LOOKER_STUDIO.md` - Arquitectura completa

### Comandos √ötiles Supabase

```sql
-- Ver estad√≠sticas de tablas
SELECT
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,
  pg_total_relation_size(schemaname||'.'||tablename) AS size_bytes
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY size_bytes DESC;

-- Contar registros por tabla
SELECT 'leads' as table_name, COUNT(*) as count FROM leads
UNION ALL
SELECT 'events', COUNT(*) FROM events
UNION ALL
SELECT 'users', COUNT(*) FROM users
UNION ALL
SELECT 'pipelines', COUNT(*) FROM pipelines;

-- Verificar √∫ltima sincronizaci√≥n
SELECT MAX(last_synced_at) FROM leads;

-- Ver leads sin tiempo de respuesta calculado
SELECT COUNT(*)
FROM leads l
LEFT JOIN response_times rt ON l.id = rt.lead_id
WHERE rt.lead_id IS NULL;
```

---

## üéØ CRITERIOS DE √âXITO

El proyecto se considera exitoso cuando:

1. ‚úÖ Script ejecuta full sync sin errores
2. ‚úÖ Datos visibles en Supabase (todas las tablas pobladas)
3. ‚úÖ Looker Studio muestra datos correctamente
4. ‚úÖ Incremental sync funciona (solo actualiza cambios)
5. ‚úÖ Tiempo de ejecuci√≥n razonable (<30 min para full sync)
6. ‚úÖ C√≥digo documentado y mantenible
7. ‚úÖ Instrucciones claras para ejecutar

---

## üìû CONTACTO

Si tienes dudas durante la implementaci√≥n, pregunta sobre:
- Estructura espec√≠fica de datos de Kommo
- Queries SQL para Looker Studio
- Optimizaciones de performance
- Manejo de casos especiales

¬°√âxito con la implementaci√≥n! üöÄ
